{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2913abdd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Import useful libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import statistics\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "##Import scrubbed retention data from Rich Grant\n",
    "df_retention = pd.read_csv('Retention1923.csv', index_col = False)\n",
    "df_retention\n",
    "\n",
    "##I do not have permission to include the scrubbed data do to FERPA concerns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab3dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FFF means first year freshmen.  Data for 19FFF, 20FFF, 21FFF, 22FFF, and 23FFF provided.\n",
    "#create dataframe with 21FFF and 22FFF only for a training and test set.  23FFF will be predicted.  \n",
    "#19FFF and 20FFF were COVID years.  In my previous work on 19FFF - 22FFF, training using the full data set\n",
    "#resulted in a poor performing model.  Using combinations of two years of data (for example:  19&20, 19&21,...) and \n",
    "#or four years of data for training all produced subtantially weaker performing models than 21&22 only.\n",
    "df_retention_21 = (df_retention[df_retention['Cohort'] == '21FFF'])\n",
    "df_retention_22 = (df_retention[df_retention['Cohort'] == '22FFF'])\n",
    "both_frames = [df_retention_21, df_retention_22]\n",
    "df_retention_21_22 = pd.concat(both_frames)\n",
    "df_retention_21_22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5969a4f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_retention_21_22.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503d1c24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#drop project ID, cohort, and birthdate columns\n",
    "df_retention_21_22.drop(columns=['Cohort', 'Birthdate', 'Project ID'], inplace=True)\n",
    "df_retention_21_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef18f864",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#replace missing data with zeros\n",
    "df_retention_21_22['Campus Orgs'] = df_retention_21_22['Campus Orgs'].fillna(0)\n",
    "df_retention_21_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd06745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change campus clubs from names to true/false\n",
    "df_retention_21_22['Campus Orgs'] = df_retention_21_22['Campus Orgs'].astype('bool')\n",
    "df_retention_21_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e66575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#view data to verify previous transformation worked as intended\n",
    "with pd.option_context('display.max_rows', None,):\n",
    "    print(df_retention_21_22['Campus Orgs'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f337cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view data to verify previous transformation worked as intended\n",
    "with pd.option_context('display.max_rows', None,):\n",
    "    print(df_retention_21_22['Campus Orgs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714e11f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#replace retained with not retained and change values from yes/no to false/true\n",
    "df_retention_21_22['Retained'].replace(('Yes', 'No'), (False,True), inplace=True)\n",
    "df_retention_21_22['not_retained']=df_retention_21_22['Retained']\n",
    "df_retention_21_22.drop(['Retained'], axis=1, inplace=True)\n",
    "df_retention_21_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e2203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace blank values for first term GPA with zeros (most likely incompletes across all classes)\n",
    "df_retention_21_22['1st Term GPA'] = df_retention_21_22['1st Term GPA'].fillna(0)\n",
    "df_retention_21_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50afc987",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Deleted cells with efforts to get native classification working with HistGradBoostingClassifier\n",
    "#Go back to earlier version to see those efforts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d726c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordinally encode nominal data.  Most of these are boolean categories.  In retrospect, one-hot-encoding would \n",
    "#have been better for 'Ethnic Race Fed' and 'Res Status'.\n",
    "category_columns = ['Ethnic Race Fed',\n",
    " 'GENDER',\n",
    " 'Pell',\n",
    " '1st Gen (No Bach)',\n",
    " 'Res Status',\n",
    " 'Athlete',\n",
    " 'Greek',\n",
    " 'Campus Orgs',\n",
    " 'RC Job',\n",
    " 'Academic Suspension (1=Yes, 0=No)']\n",
    "\n",
    "ord_enc = OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = np.nan)\n",
    "df_retention_21_22_ord = ord_enc.fit_transform(df_retention_21_22[category_columns])\n",
    "df_retention_21_22_ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd76f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify numpy array is expected size\n",
    "df_retention_21_22_ord.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52d65de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pull GPA data out of dataframe to add to ordinally encoded data\n",
    "GPA = df_retention_21_22['1st Term GPA']\n",
    "GPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb59397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#insert the GPA data into numpy array\n",
    "GPA = df_retention_21_22['1st Term GPA']\n",
    "\n",
    "KBins = KBinsDiscretizer(encode='ordinal', strategy='uniform', random_state=42, n_bins=16)\n",
    "\n",
    "GPA = GPA.values.reshape(-1, 1)\n",
    "\n",
    "GPA_KBins = KBins.fit_transform(GPA)\n",
    "\n",
    "#GPA_KBins.flatten()\n",
    "\n",
    "#GPA_KBins_list = GPA_KBins.tolist()\n",
    "#GPA_KBins_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919b6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(GPA_KBins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7aa126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify my object is a numpy array\n",
    "type(df_retention_21_22_ord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8ed43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#combine GPA data with ordinally encoded data\n",
    "df_retention_21_22_ord_wGPA = np.concatenate((GPA_KBins, df_retention_21_22_ord), axis=1)\n",
    "df_retention_21_22_ord_wGPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_retention_21_22_ord_wGPA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#partition dataframe into training and test sets\n",
    "X = df_retention_21_22_ord_wGPA\n",
    "y = df_retention_21_22[df_retention_21_22.columns[-1]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc25030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validate using best determined hyperparameters from last build of model.  GridSearch used in automating \n",
    "#previous search for hyperparamters\n",
    "\n",
    "hgb_clf = HistGradientBoostingClassifier(max_depth=3, categorical_features=[1,5], random_state=42,learning_rate=0.02, \n",
    "                                         max_iter=250)\n",
    "\n",
    "GBC_21_22_result = cross_val_score(hgb_clf, X_train, y_train, cv=5, scoring='recall', n_jobs=-1)\n",
    "#GBC_21_22 [0.79487179 0.92307692 0.79487179 0.8974359  0.94871795]\n",
    "#[0.74358974 0.84615385 0.71794872 0.82051282 0.94871795]\n",
    "print(statistics.mean(GBC_21_22_result))\n",
    "print(np.std(GBC_21_22_result))\n",
    "#mean recall 0.856\n",
    "#std 0.050\n",
    "#mean and std above correspond to recall for an algorithm and hyperparameter combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#playing around with what gets considered as a categorical feature.  Concerned about curse of dimensionality here.\n",
    "\n",
    "#hgb_clf = HistGradientBoostingClassifier(max_depth=3, random_state=42, learning_rate=0.02, max_iter=250)\n",
    "#mean recall = 0.8256410256410256\n",
    "#std recall = 0.07142763219068778\n",
    "\n",
    "#hgb_clf = HistGradientBoostingClassifier(max_depth=3, random_state=42, categorical_features=[1,2,3,4,5,6,7,8,9,10],learning_rate=0.02, \n",
    "                                        # max_iter=250)\n",
    "#mean recall =  0.8153846153846154   \n",
    "#std recall = 0.08173014077184217\n",
    "\n",
    "#dropped 8 (clubs, there are alot of them)\n",
    "#hgb_clf = HistGradientBoostingClassifier(max_depth=3, random_state=42, categorical_features=[1,2,3,4,5,6,7,9,10],learning_rate=0.02, \n",
    " #                                        max_iter=250)\n",
    "#0.8205128205128205\n",
    "#0.07777308147745178    \n",
    "\n",
    "#treated only GPA as a catagorical feature, changing the number of categories (bins).  This was fast due to small \n",
    "#dataset.  Manually changed number of bins rather than using GridSearch.\n",
    "\n",
    "#hgb_clf = HistGradientBoostingClassifier(max_depth=3, random_state=42, categorical_features=[0],learning_rate=0.02, \n",
    "                                       #  max_iter=250)\n",
    "#0.8717948717948718\n",
    "#0.06486723405473602\n",
    "\n",
    "\n",
    "#5 bins\n",
    "#0.8358974358974359\n",
    "#0.06607230116269294\n",
    "\n",
    "#4 bins\n",
    "#0.841025641025641\n",
    "#0.06153846153846155\n",
    "\n",
    "#3 bins\n",
    "#0.841025641025641\n",
    "#0.06363935203072234\n",
    "\n",
    "#10 bins\n",
    "#0.8461538461538461\n",
    "#0.06067774136512425\n",
    "\n",
    "#20 bins\n",
    "#0.8512820512820513\n",
    "#0.05475424744631442\n",
    "\n",
    "#30 bins\n",
    "#0.8461538461538461\n",
    "#0.05847053462046862\n",
    "\n",
    "#15 bins\n",
    "#0.8512820512820513\n",
    "#0.05475424744631442\n",
    "\n",
    "#25 bins\n",
    "#0.8461538461538461\n",
    "#0.06067774136512425\n",
    "\n",
    "#14 bins\n",
    "#0.8461538461538461\n",
    "#0.05847053462046862\n",
    "\n",
    "#16 bins  <---best with lowest # bins\n",
    "#0.8564102564102564\n",
    "#0.050245943441706215\n",
    "\n",
    "#17 bins\n",
    "#0.8564102564102564\n",
    "#0.050245943441706215\n",
    "\n",
    "#18 bins\n",
    "#0.8512820512820513\n",
    "#0.05475424744631442\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366fe70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y, y_hat):\n",
    "    cm_results=confusion_matrix(y, y_hat)\n",
    "    print('accuracy', accuracy_score(y, y_hat))\n",
    "    print('precision', precision_score(y, y_hat))\n",
    "    print('recall', recall_score(y, y_hat))\n",
    "    print('f1', f1_score(y, y_hat))\n",
    "    print('confusion matrix', confusion_matrix(y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check performance of model on test set\n",
    "hgb_clf.fit(X_train, y_train)\n",
    "y_hat = hgb_clf.predict(X_test)\n",
    "evaluate(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time to predict using the 23FFF data\n",
    "df_retention_23 = (df_retention[df_retention['Cohort'] == '23FFF'])\n",
    "df_retention_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccbc372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe to save index and Project ID association\n",
    "ind_ID_23 = df_retention_23['Project ID']\n",
    "ind_ID_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a57f665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop project ID, cohort, and birthdate columns\n",
    "df_retention_23.drop(columns=['Cohort', 'Birthdate', 'Project ID'], inplace=True)\n",
    "df_retention_23\n",
    "\n",
    "#not sure why I'm getting the warning below, but not when I run the same operation above.  The dataframe looks fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fe1eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change NaNs to zeros for campus orgs.  This is the first part of changing this to a boolean\n",
    "df_retention_23['Campus Orgs'] = df_retention_23['Campus Orgs'].fillna(0)\n",
    "df_retention_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b9f14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make campus organizations into a boolean.  Any campus org will become a 1.\n",
    "df_retention_23['Campus Orgs'] = df_retention_23['Campus Orgs'].astype('bool')\n",
    "df_retention_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026e8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop 'Retained' as we are predicting it for the end of spring term\n",
    "#df_retention_23.drop(['Retained'], axis=1, inplace=True)\n",
    "df_retention_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfd8124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordinal encode everything except GPA\n",
    "df_retention_23_ord = ord_enc.transform(df_retention_23[category_columns])\n",
    "df_retention_23_ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc38e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert GPA to 16 bins of values\n",
    "df_retention_23['1st Term GPA'] = df_retention_23['1st Term GPA'].fillna(0)\n",
    "GPA_23 = df_retention_23['1st Term GPA']\n",
    "\n",
    "\n",
    "GPA_23 = GPA_23.values.reshape(-1, 1)\n",
    "\n",
    "GPA_KBins_23 = KBins.transform(GPA_23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87556fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate GPA and rest of data\n",
    "df_retention_23_ord_wGPA = np.concatenate((GPA_KBins_23, df_retention_23_ord), axis=1)\n",
    "df_retention_23_ord_wGPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c38e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict results on new data\n",
    "hgb_clf.fit(X,y)\n",
    "predictions_23FFF = hgb_clf.predict(df_retention_23_ord_wGPA)\n",
    "predictions_23FFF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c8611e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ID_23 = ind_ID_23.to_numpy()\n",
    "ID_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac5b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_23 = ID_23.reshape(-1,1)\n",
    "predictions_23FFF = predictions_23FFF.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d9fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine predictions and IDs together in one array\n",
    "\n",
    "\n",
    "ID_pred_23 = np.concatenate((ID_23, predictions_23FFF), axis=1)\n",
    "ID_pred_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed42ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe of predictions and IDs\n",
    "predictions_23 = pd.DataFrame(ID_pred_23, columns=['Project ID', 'Not Retained'])\n",
    "predictions_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce2fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 'retained' column with true and false for clarity\n",
    "predictions_23['Retained'] = (predictions_23['Not Retained']==0)\n",
    "predictions_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbbb57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop not retained for clarity\n",
    "predictions_23.drop(columns=['Not Retained'], inplace=True)\n",
    "predictions_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6039223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_23.to_csv('predictions_23FFF.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb9f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_23['Retained'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d348ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data set is small, so determine 'accuracy', 'recall', and 'precision' for the \n",
    "#algorithm/preprocessing/hyperparameter combination\n",
    "\n",
    "GBC_21_22_result = cross_val_score(hgb_clf, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "print(GBC_21_22_result)\n",
    "print(statistics.mean(GBC_21_22_result))\n",
    "print(np.std(GBC_21_22_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b52e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC_21_22_result = cross_val_score(hgb_clf, X_train, y_train, cv=5, scoring='recall', n_jobs=-1)\n",
    "print(GBC_21_22_result)\n",
    "print(statistics.mean(GBC_21_22_result))\n",
    "print(np.std(GBC_21_22_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31518c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC_21_22_result = cross_val_score(hgb_clf, X_train, y_train, cv=5, scoring='precision', n_jobs=-1)\n",
    "print(GBC_21_22_result)\n",
    "print(statistics.mean(GBC_21_22_result))\n",
    "print(np.std(GBC_21_22_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe88527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
